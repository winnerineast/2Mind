import time
import base64
import sys
import hashlib
from io import BytesIO

import mss
import mss.tools
from PIL import Image
from openai import OpenAI
from colorama import init, Fore, Style

import config

# åˆå§‹åŒ–é¢œè‰²è¾“å‡º
init(autoreset=True)

class MindObserver:
    def __init__(self):
        self.client = OpenAI(base_url=config.VLLM_API_URL, api_key=config.API_KEY)
        self.last_hash = None
        self.stable_count = 0
        print(f"{Fore.CYAN}[System] 2mind Observer Initialized.")
        print(f"{Fore.CYAN}[System] Connected to Brain at: {config.VLLM_API_URL}")

    def capture_screen(self):
        """æˆªå–ä¸»å±å¹•å¹¶è¿”å› PIL Image"""
        with mss.mss() as sct:
            monitor = sct.monitors[1] # 1 æ˜¯ä¸»å±å¹•
            sct_img = sct.grab(monitor)
            img = Image.frombytes("RGB", sct_img.size, sct_img.bgra, "raw", "BGRX")
            # ç¼©æ”¾ä»¥åŠ å¿«ä¼ è¾“å’Œæ¨ç†
            img.thumbnail((config.IMAGE_RESIZE_DIM, config.IMAGE_RESIZE_DIM))
            return img

    def get_image_hash(self, img):
        """è®¡ç®—å›¾ç‰‡å“ˆå¸Œå€¼ç”¨äºæ£€æµ‹å˜åŒ–"""
        return hashlib.md5(img.tobytes()).hexdigest()

    def image_to_base64(self, img):
        buffered = BytesIO()
        img.save(buffered, format="JPEG", quality=60)
        return base64.b64encode(buffered.getvalue()).decode('utf-8')

    def ask_brain(self, b64_img):
        """å‘é€è§†è§‰è¯·æ±‚ç»™ vLLM"""
        print(f"{Fore.YELLOW}ğŸ§  Thinking...", end="\r")
        try:
            response = self.client.chat.completions.create(
                model=config.MODEL_NAME,
                messages=[
                    {
                        "role": "system",
                        "content": "You are a helpful desktop assistant. Keep your answers brief (under 30 words) and actionable."
                    },
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": "Analyze my screen. What am I doing and what should I verify next?"},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64_img}"}},
                        ],
                    }
                ],
                max_tokens=100,
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"{Fore.RED}Connection Error: {e}"

    def run(self):
        print(f"{Fore.GREEN}>>> Observer Started. Waiting for screen stability...")

        while True:
            try:
                current_img = self.capture_screen()
                current_hash = self.get_image_hash(current_img)

                if current_hash != self.last_hash:
                    # å±å¹•åœ¨åŠ¨
                    self.last_hash = current_hash
                    self.stable_count = 0
                    # sys.stdout.write(".")
                    # sys.stdout.flush()
                else:
                    # å±å¹•é™æ­¢
                    self.stable_count += 1

                # è§¦å‘æ¡ä»¶ï¼šå±å¹•é™æ­¢è¾¾åˆ°é˜ˆå€¼
                if self.stable_count == config.STABILITY_THRESHOLD:
                    print(f"\n{Fore.GREEN}[Event] Screen Stable. Capturing Context...")
                    b64 = self.image_to_base64(current_img)
                    suggestion = self.ask_brain(b64)

                    print(f"{Fore.WHITE}{Style.BRIGHT}----------------------------------------")
                    print(f"{Fore.MAGENTA}ğŸ¤– AI: {suggestion}")
                    print(f"{Fore.WHITE}{Style.BRIGHT}----------------------------------------")

                    # å¢åŠ è®¡æ•°é˜²æ­¢æ­»å¾ªç¯è§¦å‘ï¼Œç›´åˆ°ä¸‹ä¸€æ¬¡å±å¹•å˜åŠ¨
                    self.stable_count += 1

                time.sleep(config.SCREEN_CHECK_INTERVAL)

            except KeyboardInterrupt:
                print(f"\n{Fore.RED}Stopping Observer.")
                break

if __name__ == "__main__":
    app = MindObserver()
    app.run()